<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>dfs.namenode.name.dir</name> <!--메타데이터 저장 경로-->
    <value>file:///opt/hadoop/dfs/name</value>
  </property>
  <property>
    <name>dfs.blocksize</name>
    <value>134217728</value>
  </property>

  <!--HA config-->
  <property>
    <name>dfs.nameservices</name> <!-- 여기에 federation을 할 nameservice를 추가해야함-->
    <value>hadoop-cluster</value> <!--namespace를 정의-->
  </property>
  <property>
    <name>dfs.ha.namenodes.hadoop-cluster</name>
    <value>nn1, nn2</value>
  </property> <!-- namenode의 active/standby-->

  <!--rpc-address -->
  <property>
    <name>dfs.namenode.rpc-address.hadoop-cluster.nn1</name>
    <value>namenode01:8020</value>
    <!--dfs의 메타데이터 작업을 위한 통신채널-->
  </property>
  <property>
    <name>dfs.namenode.rpc-address.hadoop-cluster.nn2</name>
    <value>namenode02:8020</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.hadoop-cluster.nn1</name>
    <value>namenode01:9870</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.hadoop-cluster.nn2</name>
    <value>namenode02:9870</value>
  </property>
  
  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>sshfence
        shell(/bin/true)
    </value>
  </property>
  <!--
  <property>
      <name>dfs.ha.fencing.ssh.private-key-files</name>
      <value>~/.ssh/id_dsa</value>
  </property>
  -->
  <property>
    <name>dfs.client.use.datanode.hostname</name>
    <value>true</value>
  </property>
  
  
  <property>
    <name>dfs.client.failover.proxy.provider.hadoop-cluster</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property> <!--client가 active namenode에 연결하는 데 사용하는 java 클래스-->
  
  <!--zookeeper-->
  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value> <!--자동 장애 조치 구성-->
  </property>

  <!--datanode-->
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>file:///opt/hadoop/dfs/data</value>
  </property>
  <property>
    <name>dfs.block.size</name>
    <value>134217728</value>
  </property>  
  <property>
    <name>dfs.datanode.use.datanode.hostname</name>
    <value>true</value>
  </property>
  <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
  <!--클라이언트와 다른 데이터 노드들은 데이터 노드를 식별할 때 IP주소 대신
  호스트 이름을 사용하게끔 했음-->

  <!--journalnode-->
  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>/opt/hadoop/dfs/journal</value>
  </property>
  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://journal01:8485;journal02:8485;journal03:8485/hadoop-cluster;</value> 
    <!--journalnode URI 주소 적거야함-->
  </property>

</configuration>
