<configuration>

    <!--Where in HDFS we're going to store table files.-->
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/opt/hive/warehouse</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>hive</value>
    </property>

    <!--    https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started -->
    <property>
        <name>hive.execution.engine</name>
        <value>spark</value>
    </property>
    <!--
    <property>
        <name>spark.yarn.jars</name>
        <value>hdfs://master:9000/spark-jars/*</value>
    </property>
    -->
    <!-- To be able to execute Hive queries from Zeppelin -->
    <property>
        <name>hive.server2.enable.doAs</name>
        <value>false</value>
        <description>
            Setting this property to true will have HiveServer2 execute
            Hive operations as the user making the calls to it.
        </description>
    </property>
</configuration>